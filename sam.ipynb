{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78c56725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import leafmap\n",
    "from samgeo import SamGeo2, raster_to_vector, regularize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab9f1aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27bb43319b18422387a46ddb24e3c957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[29.6768, -95.3692], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'z…"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = leafmap.Map(center=[29.6768, -95.3692], zoom=19)\n",
    "m.add_basemap(\"SATELLITE\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25515a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = '/home/jgillan/Documents/pima_aerial/pictometry2.tif'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9c953bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27bb43319b18422387a46ddb24e3c957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=55514121.0, center=[32.071846, -110.9369725], controls=(ZoomControl(options=['position', 'zoom_in_t…"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.layers[-1].visible = False\n",
    "m.add_raster(image, layer_name=\"Image\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef152b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam2 = SamGeo2(\n",
    "        model_id=\"sam2-hiera-large\",\n",
    "        device=\"cuda\", \n",
    "        automatic=False,\n",
    "        crop_n_layers=2,\n",
    "        crop_overlap_ratio=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a993e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam2.set_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eacc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = sam2.show_map()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "504040a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from samgeo import SamGeo2\n",
    "\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d4ddcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split image into 36 tiles.\n",
      "Processing tile 1/36...\n",
      "Processing tile 2/36...\n",
      "Processing tile 3/36...\n",
      "Processing tile 4/36...\n",
      "Processing tile 5/36...\n",
      "Processing tile 6/36...\n",
      "Processing tile 7/36...\n",
      "Processing tile 8/36...\n",
      "Processing tile 9/36...\n",
      "Processing tile 10/36...\n",
      "Processing tile 11/36...\n",
      "Processing tile 12/36...\n",
      "Processing tile 13/36...\n",
      "Processing tile 14/36...\n",
      "Processing tile 15/36...\n",
      "Processing tile 16/36...\n",
      "Processing tile 17/36...\n",
      "Processing tile 18/36...\n",
      "Processing tile 19/36...\n",
      "Processing tile 20/36...\n",
      "Processing tile 21/36...\n",
      "Processing tile 22/36...\n",
      "Processing tile 23/36...\n",
      "Processing tile 24/36...\n",
      "Processing tile 25/36...\n",
      "Processing tile 26/36...\n",
      "Processing tile 27/36...\n",
      "Processing tile 28/36...\n",
      "Processing tile 29/36...\n",
      "Processing tile 30/36...\n",
      "Processing tile 31/36...\n",
      "Processing tile 32/36...\n",
      "Processing tile 33/36...\n",
      "Processing tile 34/36...\n",
      "Processing tile 35/36...\n",
      "Processing tile 36/36...\n",
      "Finished predicting 36 tile masks.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --------------------------------\n",
    "# 1. Helper function to split large images into overlapping tiles\n",
    "def split_image(image, tile_size=2048, overlap=512):\n",
    "    width, height = image.size\n",
    "    stride = tile_size - overlap\n",
    "    tiles = []\n",
    "    coords = []\n",
    "    \n",
    "    for y in range(0, height, stride):\n",
    "        for x in range(0, width, stride):\n",
    "            box = (x, y, min(x + tile_size, width), min(y + tile_size, height))\n",
    "            tile = image.crop(box)\n",
    "            tiles.append(tile)\n",
    "            coords.append((x, y))\n",
    "    return tiles, coords\n",
    "\n",
    "# --------------------------------\n",
    "# 2. Load your large image\n",
    "large_image_path = \"/home/jgillan/Documents/pima_aerial/pictometry2.tif\"\n",
    "image = Image.open(large_image_path).convert(\"RGB\")\n",
    "\n",
    "# --------------------------------\n",
    "# 3. Split image into tiles\n",
    "tile_size = 2048    # or 1024 if memory tight\n",
    "overlap = 200       # adjust overlap to avoid cutting objects\n",
    "tiles, coords = split_image(image, tile_size=tile_size, overlap=overlap)\n",
    "\n",
    "print(f\"Split image into {len(tiles)} tiles.\")\n",
    "\n",
    "# --------------------------------\n",
    "# 4. Initialize SAMGeo2 model\n",
    "sam = SamGeo2(\n",
    "    model_id=\"sam2-hiera-large\",\n",
    "    device=\"cuda\",\n",
    "    automatic=True,   # yes, use automatic mask generation on each tile\n",
    ")\n",
    "\n",
    "# --------------------------------\n",
    "# 5. Predict masks on each tile\n",
    "all_masks = []\n",
    "\n",
    "for idx, tile in enumerate(tiles):\n",
    "    print(f\"Processing tile {idx+1}/{len(tiles)}...\")\n",
    "    \n",
    "    # Convert PIL image tile to numpy array\n",
    "    tile_np = np.array(tile)\n",
    "    \n",
    "    try:\n",
    "        masks = sam.generate(tile_np)\n",
    "        all_masks.append((coords[idx], masks))\n",
    "    except RuntimeError as e:\n",
    "        print(f\"OOM at tile {idx}. Trying to recover...\")\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "# --------------------------------\n",
    "# 6. Done! Now you have masks for each tile.\n",
    "# (Optional) You can stitch them together or save them individually.\n",
    "print(f\"Finished predicting {len(all_masks)} tile masks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f46b6734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create full-sized mask canvas\n",
    "stitched_mask = np.zeros((image.height, image.width), dtype=np.uint8)\n",
    "\n",
    "for (x_offset, y_offset), masks in all_masks:\n",
    "    if masks is None:\n",
    "        continue\n",
    "    for mask in masks:\n",
    "        seg = mask['segmentation']\n",
    "        h, w = seg.shape\n",
    "        stitched_mask[y_offset:y_offset+h, x_offset:x_offset+w] = np.maximum(\n",
    "            stitched_mask[y_offset:y_offset+h, x_offset:x_offset+w],\n",
    "            seg.astype(np.uint8)\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3726a3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "downscale = 8  # try 4 or 8 depending on original image size\n",
    "small_mask = stitched_mask[::downscale, ::downscale]\n",
    "\n",
    "# Convert to transparent red RGBA image\n",
    "rgba = np.zeros((small_mask.shape[0], small_mask.shape[1], 4), dtype=np.uint8)\n",
    "rgba[small_mask > 0] = [255, 0, 0, 150]  # Red + alpha\n",
    "Image.fromarray(rgba).save(\"stitched_mask_overlay.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4180616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.warp import transform_bounds\n",
    "\n",
    "with rasterio.open(large_image_path) as src:\n",
    "    bounds = src.bounds  # (left, bottom, right, top)\n",
    "    crs = src.crs\n",
    "    bounds_latlon = transform_bounds(crs, \"EPSG:4326\", *bounds)\n",
    "\n",
    "west, south, east, north = bounds_latlon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ca6f831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c72c9435007b4f8993cd08cf24c1beeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[32.071845715852064, -110.93697267636854], controls=(ZoomControl(options=['position', 'zoom_in_text…"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import leafmap\n",
    "\n",
    "m = leafmap.Map(center=[(south + north) / 2, (west + east) / 2], zoom=16)\n",
    "m.add_basemap(\"SATELLITE\")\n",
    "\n",
    "# Add the transparent image overlay\n",
    "m.add_image(\n",
    "    \"stitched_mask_overlay.png\",\n",
    "    bounds=[[south, west], [north, east]],\n",
    "    opacity=0.5,\n",
    "    name=\"SAM Segmentation\"\n",
    ")\n",
    "\n",
    "m.add_layer_control()\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a8b0021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Assume `small_mask` is the downscaled binary mask\n",
    "# where 0 = background, 1 = object\n",
    "\n",
    "# Create an empty RGBA array\n",
    "rgba_arr = np.zeros((small_mask.shape[0], small_mask.shape[1], 4), dtype=np.uint8)\n",
    "\n",
    "# Set object pixels to red with transparency\n",
    "rgba_arr[small_mask > 0] = [255, 0, 0, 150]  # red + semi-transparent\n",
    "\n",
    "# Set background pixels to fully transparent\n",
    "# (Already zeros from np.zeros, just making it explicit)\n",
    "\n",
    "# Save as PNG\n",
    "Image.fromarray(rgba_arr).save(\"stitched_mask_rgba_clean.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b98ffee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac49cd14918d43329e00f67f0426b2ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[32.071845715852064, -110.93697267636854], controls=(ZoomControl(options=['position', 'zoom_in_text…"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import leafmap\n",
    "\n",
    "m = leafmap.Map(center=[(south + north)/2, (west + east)/2], zoom=16)\n",
    "m.add_basemap(\"SATELLITE\")\n",
    "\n",
    "m.add_image(\n",
    "    \"stitched_mask_rgba_clean.png\",\n",
    "    bounds=[[south, west], [north, east]],\n",
    "    opacity=1.0,  # use full opacity because alpha is already encoded\n",
    "    name=\"Segmented Overlay\"\n",
    ")\n",
    "\n",
    "m.add_layer_control()\n",
    "m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caa25667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downscale stitched mask for testing\n",
    "downscale_factor = 16  # very aggressive downscale\n",
    "\n",
    "tiny_mask = stitched_mask[::downscale_factor, ::downscale_factor]\n",
    "\n",
    "rgba = np.zeros((tiny_mask.shape[0], tiny_mask.shape[1], 4), dtype=np.uint8)\n",
    "rgba[tiny_mask > 0] = [255, 0, 0, 150]  # red, semi-transparent\n",
    "\n",
    "Image.fromarray(rgba).save(\"tiny_overlay.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d6fe19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b9720e0c534fc98cff9f9f72ae89c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[32.071845715852064, -110.93697267636854], controls=(ZoomControl(options=['position', 'zoom_in_text…"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import leafmap\n",
    "\n",
    "m = leafmap.Map(center=[(south + north)/2, (west + east)/2], zoom=17)\n",
    "m.add_basemap(\"SATELLITE\")\n",
    "\n",
    "m.add_image(\n",
    "    \"tiny_overlay.png\",\n",
    "    bounds=[[south, west], [north, east]],\n",
    "    opacity=1.0,\n",
    "    name=\"Tiny Overlay\"\n",
    ")\n",
    "\n",
    "m.add_layer_control()\n",
    "m\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
